{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I: Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "from math import sqrt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchvision import transforms as tfs\n",
    "import torch\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data reading and displaying data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"./FER2013/fer2013.csv\")\n",
    "datas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show expression category information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neural']\n",
    "labels_num = datas.emotion.value_counts()\n",
    "la = [0,1,2,3,4,5,6]\n",
    "la_num = [labels_num[i] for i in range(len(labels_num))]\n",
    "print(labels_num)\n",
    "plt.bar(range(len(la_num)), la_num,color='blue',tick_label=lab)  #plt.barh则是把该图变成横向的  #3fa4ff\n",
    "for a,b in zip(la,la_num):  \n",
    "    plt.text(a, b+0.05, '%.0f' % b, ha='center', va= 'bottom',fontsize=10)  \n",
    "plt.show() \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display data set classification information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = datas.Usage.value_counts()\n",
    "da = [sets[i] for i in range(len(sets))]\n",
    "set_la = ['Training','PublicTest','PrivateTest']\n",
    "print(sets)\n",
    "plt.axes(aspect=1)\n",
    "plt.title('Size of Training,PublicTest,PrivateTest sets in the image dataset')\n",
    "plt.pie(x = da,labels = set_la,autopct='%3.1f %%', shadow=True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display image pixel information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The length of photo:',len(datas.pixels[1].split()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datas[(datas.Usage == 'Training')] \n",
    "val_set = datas[(datas.Usage == 'PublicTest')]\n",
    "test_set = datas[(datas.Usage == 'PrivateTest')] \n",
    "X_train = np.array(list(map(str.split, train_set.pixels)), np.float32) #, np.float32\n",
    "X_val = np.array(list(map(str.split, val_set.pixels)), np.float32) \n",
    "X_test = np.array(list(map(str.split, test_set.pixels)), np.float32) \n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48) \n",
    "X_val = X_val.reshape(X_val.shape[0],48,48) \n",
    "X_test = X_test.reshape(X_test.shape[0],48, 48) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(train_set.emotion) \n",
    "y_val = list(val_set.emotion)\n",
    "y_test = list(test_set.emotion )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show some training samples to make sure the data is normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,8))\n",
    "for i in range(len(X_train[:35])):\n",
    "    if(y_train[i] == 0 ):\n",
    "        str_la = 'Angry'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    elif(y_train[i] == 1):\n",
    "        str_la = 'Disgust'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    elif(y_train[i] == 2):\n",
    "        str_la = 'Fear'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    elif(y_train[i] == 3):\n",
    "        str_la = 'Happy'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    elif(y_train[i] == 4):\n",
    "        str_la = 'Sad'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    elif(y_train[i] == 5):\n",
    "        str_la = 'Surprise'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    elif(y_train[i] == 6):\n",
    "        str_la = 'Neural'\n",
    "        img = Image.fromarray(np.uint8(X_train[i]))\n",
    "    y = fig.add_subplot(5,7,i+1)\n",
    "    y.imshow(img,cmap='gray')\n",
    "    plt.title(str_la)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocess = tfs.Compose([\n",
    "    tfs.ToPILImage(),\n",
    "    tfs.RandomCrop(44),\n",
    "    tfs.RandomHorizontalFlip(),\n",
    "    tfs.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "val_preprocess = tfs.Compose([\n",
    "    tfs.ToPILImage(),\n",
    "    tfs.TenCrop(44),\n",
    "    tfs.Lambda(lambda crops: torch.stack([tfs.ToTensor()(crop) for crop in crops])),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_Dataset(data.Dataset):\n",
    "    def __init__(self,X_train,labels):\n",
    "        super(Train_Dataset,self).__init__()\n",
    "        img = []\n",
    "        label = []\n",
    "        label = labels\n",
    "        a = [train_preprocess(X_train[i])  for i in range(X_train.shape[0])]\n",
    "        img = a\n",
    "        self.img = img\n",
    "        self.label=labels\n",
    "      \n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        imgs = self.img[index]\n",
    "        labels = self.label[index]\n",
    "        imgs_tensors =  imgs.type('torch.cuda.FloatTensor')\n",
    "        return imgs_tensors, labels\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Val_Dataset(data.Dataset):\n",
    "    def __init__(self,X_val,labels):\n",
    "        super(Val_Dataset,self).__init__()\n",
    "        img = []\n",
    "        label = []\n",
    "        label = labels\n",
    "        b = [val_preprocess(X_val[i])  for i in range(X_val.shape[0])]\n",
    "        img = b\n",
    "        self.img = img\n",
    "        self.label=labels\n",
    "      \n",
    "             \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        imgs = self.img[index]\n",
    "        labels = self.label[index]\n",
    "        imgs_tensors =  imgs.type('torch.cuda.FloatTensor')\n",
    "        return imgs_tensors, labels\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_train(model,dataset,batch_size):\n",
    "    val_loader = data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    result,num = 0.0, 0\n",
    "    for images,labels in val_loader:\n",
    "        images = images.cuda()\n",
    "        pre = model.forward(images)\n",
    "        pre = pre.cpu()\n",
    "        pre = np.argmax(pre.data.numpy(),axis = 1)\n",
    "        labels = labels.data.numpy()\n",
    "        result += np.sum((pre == labels))\n",
    "        num += len(images)\n",
    "    acc = result / num\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_val(model,dataset,batch_size):\n",
    "    val_loader = data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    result,num = 0.0, 0\n",
    "    for images,labels in val_loader:\n",
    "        for i in range(len(images)):\n",
    "            images[i] = images[i].cuda()\n",
    "            pre = model.forward(images[i])\n",
    "            pre =pre.cpu()\n",
    "            pre = np.argmax(pre.data.numpy().mean(0))\n",
    "            if pre == labels[i] :\n",
    "                result = result + 1\n",
    "        num += len(images)\n",
    "    acc = result / num\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = X_train\n",
    "train_labels = y_train\n",
    "Val_dataset = Val_Dataset( X_val,y_val)\n",
    "Test_dataset = Val_Dataset(X_test,y_test)\n",
    "\n",
    "batch_size= 128\n",
    "learning_rate = 0.001\n",
    "epochs= 20\n",
    "\n",
    "#resnet18\n",
    "resnet_historyloss = []\n",
    "resnet_historyacc = []\n",
    "resnet_historytrac = []\n",
    "resnet_historytestac = []\n",
    "\n",
    "#vgg19\n",
    "vgg19_historyloss = []\n",
    "vgg19_historyacc = []\n",
    "vgg19_historytrac = []\n",
    "vgg19_historytestac = []\n",
    "\n",
    "#multiple\n",
    "multiple_historyloss = []\n",
    "multiple_historyacc = []\n",
    "multiple_historytrac = []\n",
    "multiple_historytestac = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet18(train_dataset,train_labels,Val_dataset,Test_dataset,batch_size,epochs,learning_rate,momen_tum,wt_decay):\n",
    "\n",
    "    \n",
    "    resnet18 = models.resnet18()\n",
    "    resnet18.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    resnet18.fc = torch.nn.Linear(in_features=512, out_features=7, bias=True)\n",
    "    \n",
    "    model = resnet18.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function =  loss_function.cuda()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=momen_tum,weight_decay=wt_decay)\n",
    "\n",
    "    print(\"Resnet18 start training！\")\n",
    "    for epoch in range(epochs):\n",
    "        Train_dataset = Train_Dataset(train_dataset,train_labels)\n",
    "        train_loader = data.DataLoader(Train_dataset,batch_size,shuffle=True)\n",
    "        loss_rate = 0\n",
    "        model.train()\n",
    "        for images,labels in train_loader:\n",
    "            \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()            \n",
    "            output = model.forward(images)\n",
    "             \n",
    "            loss_rate = loss_function(output,labels)\n",
    "            loss_rate.backward()\n",
    "            optimizer.step()\n",
    "        resnet_historyloss.append(loss_rate.item())\n",
    "\n",
    "        \n",
    "       \n",
    "            \n",
    "        model.eval()\n",
    "        \n",
    "        acc_train = validate_train(model, Train_dataset, batch_size)\n",
    "        resnet_historytrac.append(acc_train)\n",
    "\n",
    "        acc_val = validate_val(model,Val_dataset,batch_size)\n",
    "        resnet_historyacc.append(acc_val)\n",
    "\n",
    "        acc_test = validate_val(model,Test_dataset,batch_size)\n",
    "        resnet_historytestac.append(acc_test)\n",
    "        \n",
    "        if( (epoch+1) == epochs):\n",
    "            print(\"Resnet18 moedel final result：\")\n",
    "            print('The acc_train is :',acc_train)\n",
    "            print('The acc_val is :',acc_val)\n",
    "            print('The acc_test is :',acc_test)\n",
    "            print('\\n')\n",
    "\n",
    "     \n",
    "    print(\"Resnet18 model training completed\")        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vgg19(train_dataset,train_labels,Val_dataset,Test_dataset,batch_size,epochs,learning_rate,momen_tum,wt_decay):\n",
    "\n",
    "    \n",
    "    vgg19 = models.vgg19()\n",
    "    vgg19.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    vgg19.classifier[6] = torch.nn.Linear(in_features=4096, out_features=7, bias=True)\n",
    "   \n",
    "    model = vgg19.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function =  loss_function.cuda()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=momen_tum,weight_decay=wt_decay)\n",
    "\n",
    "    print(\"VGG19 moedel starts training！\")\n",
    "    for epoch in range(epochs):\n",
    "        Train_dataset = Train_Dataset(train_dataset,train_labels)\n",
    "        train_loader = data.DataLoader(Train_dataset,batch_size,shuffle=True)\n",
    "        loss_rate = 0\n",
    "        model.train()\n",
    "        for images,labels in train_loader:\n",
    "            \n",
    "            images = images.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model.forward(images)\n",
    "            loss_rate = loss_function(output,labels)\n",
    "            loss_rate.backward()\n",
    "            optimizer.step()\n",
    "        vgg19_historyloss.append(loss_rate.item())\n",
    "\n",
    "\n",
    "        model.eval()\n",
    "    \n",
    "        acc_train = validate_train(model, Train_dataset, batch_size)\n",
    "        vgg19_historytrac.append(acc_train)\n",
    "\n",
    "        acc_val = validate_val(model,Val_dataset,batch_size)\n",
    "        vgg19_historyacc.append(acc_val)\n",
    "\n",
    "        acc_test = validate_val(model,Test_dataset,batch_size)\n",
    "        vgg19_historytestac.append(acc_test)\n",
    "\n",
    "\n",
    "        if((epoch+1) == epochs):\n",
    "            \n",
    "            print(\"VGG19 final result：\")\n",
    "            print('The acc_train is :',acc_train)\n",
    "            print('The acc_val is :',acc_val)\n",
    "            print('The acc_test is :',acc_test)\n",
    "            print('\\n')\n",
    "\n",
    "    print(\"VGG19 training completed！\")       \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = train_resnet18(train_dataset,train_labels,Val_dataset,Test_dataset,batch_size,epochs,learning_rate ,momen_tum=0.9,wt_decay = 5e-4)\n",
    "torch.save(resnet18,'fer2013_resnet18_model.pkl')\n",
    "\n",
    "vgg19 = train_vgg19(train_dataset,train_labels,Val_dataset,Test_dataset,batch_size,epochs,learning_rate ,momen_tum=0.9,wt_decay = 5e-4)\n",
    "torch.save(vgg19,'fer2013_vgg19_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torch.load(\"./FER2013//fer2013_resnet18_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vgg = torch.load(\"./FER2013/fer2013_vgg19_model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a blended model network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multiple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Multiple,self).__init__()        \n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "             nn.Linear(in_features = 14,out_features = 7),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        \n",
    "        result_1 = vgg(x)\n",
    "        result_2 = resnet(x)\n",
    "        \n",
    "        \n",
    "        result_1 = result_1.view(result_1.shape[0],-1)\n",
    "        result_2 = result_2.view(result_2.shape[0],-1)\n",
    "        result = torch.cat((result_1,result_2),1)\n",
    "        \n",
    "        y = self.fc(result)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_train(train_dataset,train_labels,Val_dataset,Test_dataset,batch_size,epochs,learning_rate,momen_tum,wt_decay):\n",
    "\n",
    "    \n",
    "    model = Multiple()\n",
    "    model = model.cuda()\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    loss_function =  loss_function.cuda()\n",
    "    \n",
    "    optimizer = optim.SGD(model.parameters(),lr=learning_rate,momentum=momen_tum,weight_decay=wt_decay)\n",
    "\n",
    "    print(\"blended model start training\")\n",
    "    for epoch in range(epochs):\n",
    "        Train_dataset = Train_Dataset(train_dataset,train_labels)\n",
    "        train_loader = data.DataLoader(Train_dataset,batch_size,shuffle=True)\n",
    "        loss_rate = 0\n",
    "        model.train()\n",
    "        for images,labels in train_loader:\n",
    "#            \n",
    "            \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(images)\n",
    "            loss_rate = loss_function(output,labels)\n",
    "            loss_rate.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "        multiple_historyloss.append(loss_rate.item())\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        #\n",
    "        acc_train = validate_train(model, Train_dataset, batch_size)\n",
    "        multiple_historytrac.append(acc_train)\n",
    "        \n",
    "        acc_val = validate_val(model,Val_dataset,batch_size)\n",
    "        multiple_historyacc.append(acc_val)\n",
    "        \n",
    "        acc_test = validate_val(model,Test_dataset,batch_size)\n",
    "        multiple_historytestac.append(acc_test)\n",
    "\n",
    "        \n",
    "        print('After {} epochs : '.format(epoch+1))\n",
    "        print('The loss_rate is :',loss_rate.item())\n",
    "        print('The acc_train is :',acc_train)\n",
    "        print('The acc_val is :',acc_val)\n",
    "        print('The acc_test is :',acc_test)\n",
    "        print('\\n')\n",
    "    \n",
    "    print(\"Blended model training completed！\")   \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multiple_train(train_dataset,train_labels,Val_dataset,Test_dataset,batch_size,epochs,learning_rate ,momen_tum=0.9,wt_decay = 5e-4)\n",
    "torch.save(model,'fer2013_multiple_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = torch.load(\"./FER2013/fer2013_blended_model.pkl\")\n",
    "resnet = torch.load(\"./FER2013//fer2013_resnet18_model.pkl\")\n",
    "vgg = torch.load(\"./FER2013/fer2013_vgg19_model.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IV: Plotting graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(historyloss,historyacc,historytrac,historytestac):\n",
    "    \n",
    "    epochs = range(len(historyacc))\n",
    "\n",
    "    plt.plot(epochs,historyloss,'r', label='train_loss')\n",
    "    plt.plot(epochs,historyacc,'b', label='acc_val')\n",
    "    plt.plot(epochs,historytrac,'g', label='acc_train')\n",
    "    plt.plot(epochs,historytestac,'y', label='acc_test')\n",
    "\n",
    "    plt.title('epoch and acc and loss_rate')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc and loss')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"resnet18\")\n",
    "plots(resnet_historyloss,resnet_historyacc,resnet_historytrac,resnet_historytestac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vgg19\")\n",
    "plots(vgg19_historyloss,vgg19_historyacc,vgg19_historytrac,vgg19_historytestac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"blended model\")\n",
    "plots(multiple_historyloss,multiple_historyacc,multiple_historytrac,multiple_historytestac)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V: Drawing confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model,dataset,batch_size):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    label = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neural']\n",
    "    tick_marks = np.array(range(len(label))) + 0.5\n",
    "    \n",
    "    val_loader = data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    for images,labels in val_loader:\n",
    "        for i in range(len(images)):\n",
    "            images[i] = images[i].cuda()\n",
    "            pre = model.forward(images[i])\n",
    "            pre =pre.cpu()\n",
    "            pre = np.argmax(pre.data.numpy().mean(0))\n",
    "            y_true.append(labels[i])\n",
    "            y_pred.append(pre)\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    np.set_printoptions(precision=2)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plt.figure(figsize=(8, 6), dpi=80)\n",
    "\n",
    "    ind_array = np.arange(len(label))\n",
    "    x, y = np.meshgrid(ind_array, ind_array)\n",
    "    for x_val, y_val in zip(x.flatten(), y.flatten()):\n",
    "        c = cm_normalized[y_val][x_val]\n",
    "        if c > 0.01:\n",
    "            plt.text(x_val, y_val, \"%0.2f\" % (c,), color='red', fontsize=10, va='center', ha='center')\n",
    "    plt.gca().set_xticks(tick_marks, minor=True)\n",
    "    plt.gca().set_yticks(tick_marks, minor=True)\n",
    "    plt.gca().xaxis.set_ticks_position('none')\n",
    "    plt.gca().yaxis.set_ticks_position('none')\n",
    "    plt.grid(True, which='minor', linestyle='-')\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "\n",
    "   \n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    xlocations = np.array(range(len(label)))\n",
    "    plt.xticks(xlocations, label, rotation=70)\n",
    "    plt.yticks(xlocations, label)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = list(val_set.emotion)\n",
    "dataset = Val_Dataset( X_val,y_val)\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"vgg19 model  Confusion Matrix\")\n",
    "# plot_confusion_matrix(vgg,dataset,batch_size)\n",
    "\n",
    "# print(\"resnet18 model Confusion Matrix\")\n",
    "# plot_confusion_matrix(resnet,dataset,batch_size)\n",
    "\n",
    "print(\"blended model Confusion Matrix\")\n",
    "plot_confusion_matrix(mul,dataset,batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VI: Model loading and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('fer2013_multiple_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = list(val_set.emotion)\n",
    "y_test = list(test_set.emotion )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Va_dataset = Val_Dataset( X_val,y_val)\n",
    "acc_val = validate_val(model,Va_dataset,128)\n",
    "print('accuracy：',acc_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seven: Random individual pictures for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,dataset,batch_size):\n",
    "    val_loader = data.DataLoader(dataset,batch_size,shuffle=True)\n",
    "    result,num = 0.0, 0\n",
    "    y_pred = []\n",
    "    \n",
    "    for images,labels in val_loader:\n",
    "        for i in range(len(images)):\n",
    "            images[i] = images[i].cuda()\n",
    "            pre = model.forward(images[i])\n",
    "            pre =pre.cpu()\n",
    "            pre = np.argmax(pre.data.numpy().mean(0))\n",
    "            y_pred.append(pre)\n",
    "    return y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All categories of images were tested separately in a certain range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1000\n",
    "j = 1100\n",
    "img_val = X_val[i:j]\n",
    "label_val = y_val[i:j]\n",
    "im_0= []\n",
    "im_1= []\n",
    "im_2= []\n",
    "im_3= []\n",
    "im_4= []\n",
    "im_5= []\n",
    "im_6= []\n",
    "la_0 = []\n",
    "la_1 = []\n",
    "la_2 = []\n",
    "la_3 = []\n",
    "la_4 = []\n",
    "la_5 = []\n",
    "la_6 = []\n",
    "for k in range(len(img_val)):\n",
    "    \n",
    "    if(label_val[k] == 0):\n",
    "        \n",
    "        im_0.append(img_val[k])\n",
    "        la_0.append(0)\n",
    "                \n",
    "    elif(label_val[k] == 1):\n",
    "        \n",
    "        im_1.append(img_val[k])\n",
    "        la_1.append(1)\n",
    "        \n",
    "    elif(label_val[k] ==2):\n",
    "        \n",
    "        im_2.append(img_val[k])\n",
    "        la_2.append(2)\n",
    "        \n",
    "    elif(label_val[k] ==3):\n",
    "        \n",
    "        im_3.append(img_val[k])\n",
    "        la_3.append(3)\n",
    "        \n",
    "    elif(label_val[k] ==4):\n",
    "        \n",
    "        im_4.append(img_val[k])\n",
    "        la_4.append(4)\n",
    "        \n",
    "    elif(label_val[k] ==5):\n",
    "        \n",
    "        im_5.append(img_val[k])\n",
    "        la_5.append(5)\n",
    "        \n",
    "    elif(label_val[k] ==6):\n",
    "        \n",
    "        im_6.append(img_val[k])\n",
    "        la_6.append(6)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lis = []\n",
    "y_lis = []\n",
    "x_lis.append(np.array(im_0))\n",
    "x_lis.append(np.array(im_1))\n",
    "x_lis.append(np.array(im_2))\n",
    "x_lis.append(np.array(im_3))\n",
    "x_lis.append(np.array(im_4))\n",
    "x_lis.append(np.array(im_5))\n",
    "x_lis.append(np.array(im_6))\n",
    "y_lis.append(la_0)\n",
    "y_lis.append(la_1)\n",
    "y_lis.append(la_2)\n",
    "y_lis.append(la_3)\n",
    "y_lis.append(la_4)\n",
    "y_lis.append(la_5)\n",
    "y_lis.append(la_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neural']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_lis)):\n",
    "    Va_dataset = Val_Dataset( x_lis[i],y_lis[i])\n",
    "    pre = validate(model,Va_dataset,1)\n",
    "    print(labels[y_lis[i][0]])\n",
    "    print('result：\\t',y_lis[i])\n",
    "    print('predicted result\\t',pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
